{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed2bf908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23a77a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv(r\"C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\factiva_articles_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "418c523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles_sample = df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f217d82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Doc_ID', 'Date', 'Headline', 'Content'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles_sample.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e44b84e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7028, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5b6b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ollama_prompt(model_name, prompt_text):\n",
    "    try:\n",
    "        command = ['ollama', 'run', model_name]\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=prompt_text)\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error: {stderr}\")\n",
    "            return None\n",
    "\n",
    "        return stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82dfd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a financial summarizer focused only on gold-related events.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Summarize ONLY the parts related to gold: gold prices, gold futures, bullion, gold demand, safe haven, inflation impact on gold.\n",
    "- Ignore content about equities, bonds, crypto, general economy unless it causally impacts gold.\n",
    "- If no gold-related discussion found, output: {{\"gold_summary\": \"No relevant gold content.\"}}\n",
    "\n",
    "Important: output ONLY valid JSON with this format:\n",
    "{{\"gold_summary\": \"...\"}}.\n",
    "\"\"\"\n",
    "    return prompt_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "712222a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gold_summary(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_summary', '')\n",
    "        else:\n",
    "            return ''\n",
    "    except json.JSONDecodeError:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ed37d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_similarity(cos_sim):\n",
    "    norm = (cos_sim + 1) / 2  # map (-1,1) ‚Üí (0,1)\n",
    "    scaled = 0.1 + 0.9 * norm # map (0,1) ‚Üí (0.1,1.0)\n",
    "    return round(scaled, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_and_score(df, model_name, output_csv):\n",
    "    #df = pd.read_csv(input_csv)\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    df['Content'] = df['Content'].astype(str)  # Ensure content is string type\n",
    "\n",
    "    # Load sentence-transformers model\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    prototype_sentence = \"gold price, bullion, inflation, gold futures, safe haven\"\n",
    "    proto_emb = embed_model.encode(prototype_sentence, convert_to_tensor=True)\n",
    "\n",
    "    summaries = []\n",
    "    scores = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        Content = row['Content']\n",
    "\n",
    "        prompt = create_prompt(Content)\n",
    "        response = run_ollama_prompt(model_name, prompt)\n",
    "        if not response:\n",
    "            gold_summary = \"No summary generated.\"\n",
    "            relevance_score = 0.1\n",
    "        else:\n",
    "            gold_summary = extract_gold_summary(response)\n",
    "\n",
    "            # Embed gold summary\n",
    "            summary_emb = embed_model.encode(gold_summary, convert_to_tensor=True)\n",
    "            cos_sim = util.cos_sim(summary_emb, proto_emb).item()\n",
    "            relevance_score = normalize_similarity(cos_sim)\n",
    "\n",
    "        summaries.append(gold_summary)\n",
    "        scores.append(relevance_score)\n",
    "\n",
    "    df['gold_summary'] = summaries\n",
    "    df['gold_relevance_score'] = scores\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Finished processing. Output saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3695e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:19<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Finished processing. Output saved to C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\all_gold_summarized_scored_articles_llama3.2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Ollama runner ---\n",
    "def run_ollama_prompt(model_name, prompt_text):\n",
    "    try:\n",
    "        command = ['ollama', 'run', model_name]\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=prompt_text)\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error: {stderr}\")\n",
    "            return None\n",
    "\n",
    "        return stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Summarization Prompt ---\n",
    "def create_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a financial summarizer focused only on gold-related events.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Summarize ONLY the parts related to gold: gold prices, gold futures, bullion, gold demand, safe haven, inflation impact on gold.\n",
    "- Ignore content about equities, bonds, crypto, general economy unless it causally impacts gold.\n",
    "- If no gold-related discussion found, output: {{\"gold_summary\": \"No relevant gold content.\"}}\n",
    "\n",
    "Important: output ONLY valid JSON with this format:\n",
    "{{\"gold_summary\": \"...\"}}.\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- Parse LLM JSON safely ---\n",
    "def extract_gold_summary(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_summary', '')\n",
    "        else:\n",
    "            return ''\n",
    "    except json.JSONDecodeError:\n",
    "        return ''\n",
    "\n",
    "# --- Normalize cosine similarity ---\n",
    "def normalize_similarity(cos_sim):\n",
    "    norm = (cos_sim + 1) / 2  # map (-1,1) ‚Üí (0,1)\n",
    "    scaled = 0.1 + 0.9 * norm # map (0,1) ‚Üí (0.1,1.0)\n",
    "    return round(scaled, 4)\n",
    "\n",
    "# --- Main Processor ---\n",
    "def summarize_and_score(df, model_name, output_csv):\n",
    "    # Load sentence-transformers model\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    prototype_sentence = \"gold price, bullion, inflation, gold futures, safe haven\"\n",
    "    proto_emb = embed_model.encode(prototype_sentence, convert_to_tensor=True)\n",
    "\n",
    "    summaries = []\n",
    "    scores = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        content = row['Content']  # Important: Using \"Content\" not \"content\"\n",
    "\n",
    "        prompt = create_prompt(content)\n",
    "        response = run_ollama_prompt(model_name, prompt)\n",
    "        if not response:\n",
    "            gold_summary = \"No summary generated.\"\n",
    "            relevance_score = 0.1\n",
    "        else:\n",
    "            gold_summary = extract_gold_summary(response)\n",
    "\n",
    "            # Embed gold summary\n",
    "            summary_emb = embed_model.encode(gold_summary, convert_to_tensor=True)\n",
    "            cos_sim = util.cos_sim(summary_emb, proto_emb).item()\n",
    "            relevance_score = normalize_similarity(cos_sim)\n",
    "\n",
    "        summaries.append(gold_summary)\n",
    "        scores.append(relevance_score)\n",
    "\n",
    "    df['gold_summary'] = summaries\n",
    "    df['gold_relevance_score'] = scores\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Finished processing. Output saved to {output_csv}\")\n",
    "\n",
    "# --- Running Section --- #\n",
    "if __name__ == \"__main__\":\n",
    "    # Instead of loading CSV, using provided DataFrame\n",
    "    df = df_articles_sample.copy()  # Your in-memory sample DataFrame\n",
    "    output_csv = r\"C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\all_gold_summarized_scored_articles_llama3.2.csv\"\n",
    "    model_name = \"llama3.2\"  # or your local Llama model\n",
    "\n",
    "    summarize_and_score(df, model_name, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3bd1f8",
   "metadata": {},
   "source": [
    "## inluding the cause and effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "536e3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:24<00:00,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Finished processing. Output saved to C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\causal_gold_articles.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Ollama LLM Runner ---\n",
    "def run_ollama_prompt(model_name, prompt_text):\n",
    "    try:\n",
    "        command = ['ollama', 'run', model_name]\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=prompt_text)\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error: {stderr}\")\n",
    "            return None\n",
    "\n",
    "        return stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Causal Gold Extraction Prompt ---\n",
    "def create_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a causal summarizer focused on the gold market.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Analyze only gold-related parts.\n",
    "- Identify clear CAUSE (reason) and EFFECT (impact on gold prices, volatility, demand).\n",
    "- Extract clean cause-effect pairs.\n",
    "- Only output JSON with exact structure:\n",
    "\n",
    "{{\n",
    "  \"gold_causal_summary\": [\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }},\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Notes:\n",
    "- Be very specific.\n",
    "- If no gold-related causality is found, output: {{\"gold_causal_summary\": []}}\n",
    "- Do not summarize unrelated parts of the article.\n",
    "- No extra text outside JSON.\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- Parse LLM JSON Output ---\n",
    "def extract_causal_pairs(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_causal_summary', [])\n",
    "        else:\n",
    "            return []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "# --- Normalize Cosine Similarity ---\n",
    "def normalize_similarity(cos_sim):\n",
    "    norm = (cos_sim + 1) / 2  # map (-1,1) ‚Üí (0,1)\n",
    "    scaled = 0.1 + 0.9 * norm # map (0,1) ‚Üí (0.1,1.0)\n",
    "    return round(scaled, 4)\n",
    "\n",
    "# --- Main Processor ---\n",
    "def summarize_and_score(df, model_name, output_csv):\n",
    "    # Load sentence-transformers model\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    prototype_sentence = \"gold price, bullion, inflation, gold futures, safe haven\"\n",
    "    proto_emb = embed_model.encode(prototype_sentence, convert_to_tensor=True)\n",
    "\n",
    "    cause_list = []\n",
    "    effect_list = []\n",
    "    cause_effect_summary_list = []\n",
    "    similarity_scores = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        content = row['Content']\n",
    "\n",
    "        prompt = create_prompt(content)\n",
    "        response = run_ollama_prompt(model_name, prompt)\n",
    "        if not response:\n",
    "            causes = []\n",
    "        else:\n",
    "            causes = extract_causal_pairs(response)\n",
    "\n",
    "        if causes:\n",
    "            # If multiple causes-effects, combine them\n",
    "            cause_texts = [c['cause'] for c in causes]\n",
    "            effect_texts = [c['effect'] for c in causes]\n",
    "            joined_cause_effect = [\"Cause: \" + c['cause'] + \" --> Effect: \" + c['effect'] for c in causes]\n",
    "\n",
    "            cause_text = \" || \".join(cause_texts)\n",
    "            effect_text = \" || \".join(effect_texts)\n",
    "            cause_effect_summary = \" || \".join(joined_cause_effect)\n",
    "        else:\n",
    "            cause_text = \"No gold cause identified.\"\n",
    "            effect_text = \"No gold effect identified.\"\n",
    "            cause_effect_summary = \"No gold causality found.\"\n",
    "\n",
    "        # Embed the cause_effect_summary for scoring\n",
    "        summary_emb = embed_model.encode(cause_effect_summary, convert_to_tensor=True)\n",
    "        cos_sim = util.cos_sim(summary_emb, proto_emb).item()\n",
    "        relevance_score = normalize_similarity(cos_sim)\n",
    "\n",
    "        cause_list.append(cause_text)\n",
    "        effect_list.append(effect_text)\n",
    "        cause_effect_summary_list.append(cause_effect_summary)\n",
    "        similarity_scores.append(relevance_score)\n",
    "\n",
    "    # Add new columns\n",
    "    df['gold_cause'] = cause_list\n",
    "    df['gold_effect'] = effect_list\n",
    "    df['gold_cause_effect_summary'] = cause_effect_summary_list\n",
    "    df['gold_relevance_score'] = similarity_scores\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Finished processing. Output saved to {output_csv}\")\n",
    "\n",
    "# --- RUNNING SECTION --- #\n",
    "if __name__ == \"__main__\":\n",
    "    df = df_articles_sample.copy()  # Your provided DataFrame\n",
    "    output_csv = r\"C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\causal_gold_articles.csv\"\n",
    "    model_name = \"llama3.1\"\n",
    "\n",
    "    summarize_and_score(df, model_name, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17e4c9",
   "metadata": {},
   "source": [
    "##  extedning it to next level adding the BERT Embeddings also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "285eae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [02:34<00:00, 15.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Finished processing. Output saved to C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\causal_gold_articles_full.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Ollama LLM Runner ---\n",
    "def run_ollama_prompt(model_name, prompt_text):\n",
    "    try:\n",
    "        command = ['ollama', 'run', model_name]\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=prompt_text)\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error: {stderr}\")\n",
    "            return None\n",
    "\n",
    "        return stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Causal Gold Extraction Prompt ---\n",
    "def create_causal_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a causal summarizer focused on the gold market.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Analyze only gold-related parts.\n",
    "- Identify clear CAUSE (reason) and EFFECT (impact on gold prices, volatility, demand).\n",
    "- Extract clean cause-effect pairs.\n",
    "- Only output JSON with exact structure:\n",
    "\n",
    "{{\n",
    "  \"gold_causal_summary\": [\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }},\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Notes:\n",
    "- If no gold-related causality found, output: {{\"gold_causal_summary\": []}}\n",
    "- No extra text, only valid JSON.\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- General Gold Summary Prompt ---\n",
    "def create_general_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a financial summarizer.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Summarize briefly (2-3 sentences) any discussion related to GOLD: prices, futures, volatility, safe haven demand.\n",
    "- If no gold-related content found, output: {{\"gold_summary\": \"No gold-related content found.\"}}\n",
    "\n",
    "Output ONLY valid JSON:\n",
    "\n",
    "{{\n",
    "  \"gold_summary\": \"....\"\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- Parse LLM JSON Outputs ---\n",
    "def extract_causal_pairs(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_causal_summary', [])\n",
    "        else:\n",
    "            return []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def extract_general_summary(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_summary', '')\n",
    "        else:\n",
    "            return ''\n",
    "    except json.JSONDecodeError:\n",
    "        return ''\n",
    "\n",
    "# --- Normalize Cosine Similarity ---\n",
    "def normalize_similarity(cos_sim):\n",
    "    norm = (cos_sim + 1) / 2  # map (-1,1) ‚Üí (0,1)\n",
    "    scaled = 0.1 + 0.9 * norm # map (0,1) ‚Üí (0.1,1.0)\n",
    "    return round(scaled, 4)\n",
    "\n",
    "# --- Main Processor ---\n",
    "def summarize_and_score(df, model_name, output_csv):\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    prototype_sentence = \"gold price, bullion, inflation, gold futures, safe haven\"\n",
    "    proto_emb = embed_model.encode(prototype_sentence, convert_to_tensor=True)\n",
    "\n",
    "    cause_list = []\n",
    "    effect_list = []\n",
    "    cause_effect_summary_list = []\n",
    "    general_summary_list = []\n",
    "    general_embedding_list = []\n",
    "    similarity_scores = []\n",
    "    bad_rows = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        try:\n",
    "            content = row['Content']\n",
    "\n",
    "            # Causal extraction\n",
    "            causal_prompt = create_causal_prompt(content)\n",
    "            causal_response = run_ollama_prompt(model_name, causal_prompt)\n",
    "            causes = extract_causal_pairs(causal_response) if causal_response else []\n",
    "\n",
    "            if causes:\n",
    "                cause_texts = [c['cause'] for c in causes]\n",
    "                effect_texts = [c['effect'] for c in causes]\n",
    "                joined_cause_effect = [\"Cause: \" + c['cause'] + \" --> Effect: \" + c['effect'] for c in causes]\n",
    "\n",
    "                cause_text = \" || \".join(cause_texts)\n",
    "                effect_text = \" || \".join(effect_texts)\n",
    "                cause_effect_summary = \" || \".join(joined_cause_effect)\n",
    "            else:\n",
    "                cause_text = \"No gold cause identified.\"\n",
    "                effect_text = \"No gold effect identified.\"\n",
    "                cause_effect_summary = \"No gold causality found.\"\n",
    "\n",
    "            # General summarization\n",
    "            general_prompt = create_general_prompt(content)\n",
    "            general_response = run_ollama_prompt(model_name, general_prompt)\n",
    "            gold_general_summary = extract_general_summary(general_response) if general_response else \"No gold-related content found.\"\n",
    "\n",
    "            # Embedding the general summary\n",
    "            general_emb = embed_model.encode(gold_general_summary, convert_to_numpy=True).tolist()\n",
    "\n",
    "            # Relevance scoring\n",
    "            summary_emb = embed_model.encode(cause_effect_summary, convert_to_tensor=True)\n",
    "            cos_sim = util.cos_sim(summary_emb, proto_emb).item()\n",
    "            relevance_score = normalize_similarity(cos_sim)\n",
    "\n",
    "            # Save\n",
    "            cause_list.append(cause_text)\n",
    "            effect_list.append(effect_text)\n",
    "            cause_effect_summary_list.append(cause_effect_summary)\n",
    "            general_summary_list.append(gold_general_summary)\n",
    "            general_embedding_list.append(general_emb)\n",
    "            similarity_scores.append(relevance_score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Skipping row {idx} due to error: {e}\")\n",
    "            bad_rows.append(row)\n",
    "\n",
    "    # Final dataframe\n",
    "    df['gold_cause'] = cause_list\n",
    "    df['gold_effect'] = effect_list\n",
    "    df['gold_cause_effect_summary'] = cause_effect_summary_list\n",
    "    df['gold_general_summary'] = general_summary_list\n",
    "    df['gold_general_embedding'] = general_embedding_list\n",
    "    df['gold_relevance_score'] = similarity_scores\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Finished processing. Output saved to {output_csv}\")\n",
    "\n",
    "    # Save bad rows separately\n",
    "    if bad_rows:\n",
    "        bad_rows_df = pd.DataFrame(bad_rows)\n",
    "        bad_rows_output = output_csv.replace(\".csv\", \"_bad_rows.csv\")\n",
    "        bad_rows_df.to_csv(bad_rows_output, index=False)\n",
    "        print(f\"\\nüö® Saved bad rows separately to {bad_rows_output}\")\n",
    "\n",
    "# --- RUNNING SECTION --- #\n",
    "if __name__ == \"__main__\":\n",
    "    df = df_articles_sample.copy()  # your sample df\n",
    "    output_csv = r\"C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\causal_gold_articles_full.csv\"\n",
    "    model_name = \"llama3.1\"\n",
    "\n",
    "    summarize_and_score(df, model_name, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab92c196",
   "metadata": {},
   "source": [
    "## the problem befor is even though we have cause and effects its giving blank general summaries and that was handled here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d96813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|          | 6/7028 [00:19<6:01:06,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Warning: Skipping row 5 due to error: 'effect'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|          | 20/7028 [01:24<8:15:12,  4.24s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 212\u001b[0m\n\u001b[0;32m    209\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbalaj\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcode_files\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBrahmanda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcontext_aware_risk_methodology\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mevent_causal_prediction_system\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcausal_gold_articles_full_articles.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    210\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 212\u001b[0m \u001b[43msummarize_and_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_csv\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[51], line 138\u001b[0m, in \u001b[0;36msummarize_and_score\u001b[1;34m(df, model_name, output_csv)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Causal extraction\u001b[39;00m\n\u001b[0;32m    137\u001b[0m causal_prompt \u001b[38;5;241m=\u001b[39m create_causal_prompt(content)\n\u001b[1;32m--> 138\u001b[0m causal_response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ollama_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m causes \u001b[38;5;241m=\u001b[39m extract_causal_pairs(causal_response) \u001b[38;5;28;01mif\u001b[39;00m causal_response \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m causes:\n",
      "Cell \u001b[1;32mIn[51], line 20\u001b[0m, in \u001b[0;36mrun_ollama_prompt\u001b[1;34m(model_name, prompt_text)\u001b[0m\n\u001b[0;32m     12\u001b[0m command \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m, model_name]\n\u001b[0;32m     13\u001b[0m process \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[0;32m     14\u001b[0m     command,\n\u001b[0;32m     15\u001b[0m     stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1628\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1628\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1630\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1149\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1169\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1170\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Ollama LLM Runner ---\n",
    "def run_ollama_prompt(model_name, prompt_text):\n",
    "    try:\n",
    "        command = ['ollama', 'run', model_name]\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=prompt_text)\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error: {stderr}\")\n",
    "            return None\n",
    "\n",
    "        return stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Causal Gold Extraction Prompt ---\n",
    "def create_causal_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a causal summarizer focused on the gold market.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Analyze only gold-related parts.\n",
    "- Identify clear CAUSE (reason) and EFFECT (impact on gold prices, volatility, demand).\n",
    "- Extract clean cause-effect pairs.\n",
    "- Only output JSON with exact structure:\n",
    "\n",
    "{{\n",
    "  \"gold_causal_summary\": [\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }},\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Notes:\n",
    "- If no gold-related causality found, output: {{\"gold_causal_summary\": []}}\n",
    "- No extra text, only valid JSON.\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- General Gold Summary Prompt ---\n",
    "def create_general_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a financial summarizer.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Summarize briefly (2-3 sentences) any discussion related to GOLD: prices, futures, volatility, safe haven demand.\n",
    "- If no gold-related content found, output: {{\"gold_summary\": \"No gold-related content found.\"}}\n",
    "\n",
    "Output ONLY valid JSON:\n",
    "\n",
    "{{\n",
    "  \"gold_summary\": \"....\"\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- Parse LLM JSON Outputs ---\n",
    "def extract_causal_pairs(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_causal_summary', [])\n",
    "        else:\n",
    "            return []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def extract_general_summary(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_summary', '')\n",
    "        else:\n",
    "            return ''\n",
    "    except json.JSONDecodeError:\n",
    "        return ''\n",
    "\n",
    "# --- Normalize Cosine Similarity ---\n",
    "def normalize_similarity(cos_sim):\n",
    "    norm = (cos_sim + 1) / 2  # map (-1,1) ‚Üí (0,1)\n",
    "    scaled = 0.1 + 0.9 * norm # map (0,1) ‚Üí (0.1,1.0)\n",
    "    return round(scaled, 4)\n",
    "\n",
    "# --- Main Processor ---\n",
    "def summarize_and_score(df, model_name, output_csv):\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    prototype_sentence = \"gold price, bullion, inflation, gold futures, safe haven\"\n",
    "    proto_emb = embed_model.encode(prototype_sentence, convert_to_tensor=True)\n",
    "\n",
    "    cause_list = []\n",
    "    effect_list = []\n",
    "    cause_effect_summary_list = []\n",
    "    general_summary_list = []\n",
    "    general_embedding_list = []\n",
    "    similarity_scores = []\n",
    "    causal_only_flags = []\n",
    "    bad_rows = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        try:\n",
    "            content = row['Content']\n",
    "\n",
    "            # Causal extraction\n",
    "            causal_prompt = create_causal_prompt(content)\n",
    "            causal_response = run_ollama_prompt(model_name, causal_prompt)\n",
    "            causes = extract_causal_pairs(causal_response) if causal_response else []\n",
    "\n",
    "            if causes:\n",
    "                cause_texts = [c['cause'] for c in causes]\n",
    "                effect_texts = [c['effect'] for c in causes]\n",
    "                joined_cause_effect = [\"Cause: \" + c['cause'] + \" --> Effect: \" + c['effect'] for c in causes]\n",
    "\n",
    "                cause_text = \" || \".join(cause_texts)\n",
    "                effect_text = \" || \".join(effect_texts)\n",
    "                cause_effect_summary = \" || \".join(joined_cause_effect)\n",
    "            else:\n",
    "                cause_text = \"No gold cause identified.\"\n",
    "                effect_text = \"No gold effect identified.\"\n",
    "                cause_effect_summary = \"No gold causality found.\"\n",
    "\n",
    "            # General summarization\n",
    "            general_prompt = create_general_prompt(content)\n",
    "            general_response = run_ollama_prompt(model_name, general_prompt)\n",
    "            gold_general_summary = extract_general_summary(general_response) if general_response else \"No gold-related content found.\"\n",
    "\n",
    "            # Fallback: if no summary but causes exist\n",
    "            if gold_general_summary == \"No gold-related content found.\" and causes:\n",
    "                fallback_summary = f\"This article discusses gold causally, mentioning: {', '.join(cause_texts)}.\"\n",
    "                gold_general_summary = fallback_summary\n",
    "                causal_only_flags.append(True)\n",
    "            else:\n",
    "                causal_only_flags.append(False)\n",
    "\n",
    "            # Embedding the general summary\n",
    "            general_emb = embed_model.encode(gold_general_summary, convert_to_numpy=True).tolist()\n",
    "\n",
    "            # Relevance scoring\n",
    "            summary_emb = embed_model.encode(cause_effect_summary, convert_to_tensor=True)\n",
    "            cos_sim = util.cos_sim(summary_emb, proto_emb).item()\n",
    "            relevance_score = normalize_similarity(cos_sim)\n",
    "\n",
    "            # Save\n",
    "            cause_list.append(cause_text)\n",
    "            effect_list.append(effect_text)\n",
    "            cause_effect_summary_list.append(cause_effect_summary)\n",
    "            general_summary_list.append(gold_general_summary)\n",
    "            general_embedding_list.append(general_emb)\n",
    "            similarity_scores.append(relevance_score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Skipping row {idx} due to error: {e}\")\n",
    "            bad_rows.append(row)\n",
    "\n",
    "    # Add final columns\n",
    "    df['gold_cause'] = cause_list\n",
    "    df['gold_effect'] = effect_list\n",
    "    df['gold_cause_effect_summary'] = cause_effect_summary_list\n",
    "    df['gold_general_summary'] = general_summary_list\n",
    "    df['gold_general_embedding'] = general_embedding_list\n",
    "    df['gold_relevance_score'] = similarity_scores\n",
    "    df['causal_only'] = causal_only_flags\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Finished processing. Output saved to {output_csv}\")\n",
    "\n",
    "    # Save bad rows separately\n",
    "    if bad_rows:\n",
    "        bad_rows_df = pd.DataFrame(bad_rows)\n",
    "        bad_rows_output = output_csv.replace(\".csv\", \"_bad_rows.csv\")\n",
    "        bad_rows_df.to_csv(bad_rows_output, index=False)\n",
    "        print(f\"\\nüö® Saved bad rows separately to {bad_rows_output}\")\n",
    "\n",
    "# --- RUNNING SECTION --- #\n",
    "if __name__ == \"__main__\":\n",
    "    df = df_articles  # your sample DataFrame\n",
    "    output_csv = r\"C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\causal_gold_articles_full_articles.csv\"\n",
    "    model_name = \"llama3.2\"\n",
    "\n",
    "    summarize_and_score(df, model_name, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18e76e",
   "metadata": {},
   "source": [
    "# adding the good rows and the bad rows to the same csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# --- Ollama LLM Runner ---\n",
    "def run_ollama_prompt(model_name, prompt_text):\n",
    "    try:\n",
    "        command = ['ollama', 'run', model_name]\n",
    "        process = subprocess.Popen(\n",
    "            command,\n",
    "            stdin=subprocess.PIPE,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        stdout, stderr = process.communicate(input=prompt_text)\n",
    "\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error: {stderr}\")\n",
    "            return None\n",
    "\n",
    "        return stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Causal Gold Extraction Prompt ---\n",
    "def create_causal_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a causal summarizer focused on the gold market.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Analyze only gold-related parts.\n",
    "- Identify clear CAUSE (reason) and EFFECT (impact on gold prices, volatility, demand).\n",
    "- Extract clean cause-effect pairs.\n",
    "- Only output JSON with exact structure:\n",
    "\n",
    "{{\n",
    "  \"gold_causal_summary\": [\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }},\n",
    "    {{\n",
    "      \"cause\": \"....\",\n",
    "      \"effect\": \"....\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Notes:\n",
    "- If no gold-related causality found, output: {{\"gold_causal_summary\": []}}\n",
    "- No extra text, only valid JSON.\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- General Gold Summary Prompt ---\n",
    "def create_general_prompt(article_content):\n",
    "    prompt_text = f\"\"\"\n",
    "You are a financial summarizer.\n",
    "\n",
    "Here is a news article:\n",
    "---\n",
    "{article_content}\n",
    "---\n",
    "\n",
    "Task:\n",
    "- Summarize briefly (2-3 sentences) any discussion related to GOLD: prices, futures, volatility, safe haven demand.\n",
    "- If no gold-related content found, output: {{\"gold_summary\": \"No gold-related content found.\"}}\n",
    "\n",
    "Output ONLY valid JSON:\n",
    "\n",
    "{{\n",
    "  \"gold_summary\": \"....\"\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt_text.strip()\n",
    "\n",
    "# --- Parse LLM JSON Outputs ---\n",
    "def extract_causal_pairs(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_causal_summary', [])\n",
    "        else:\n",
    "            return []\n",
    "    except json.JSONDecodeError:\n",
    "        return []\n",
    "\n",
    "def extract_general_summary(ollama_response):\n",
    "    try:\n",
    "        json_match = re.search(r'\\{.*\\}', ollama_response, re.DOTALL)\n",
    "        if json_match:\n",
    "            parsed = json.loads(json_match.group(0))\n",
    "            return parsed.get('gold_summary', '')\n",
    "        else:\n",
    "            return ''\n",
    "    except json.JSONDecodeError:\n",
    "        return ''\n",
    "\n",
    "# --- Normalize Cosine Similarity ---\n",
    "def normalize_similarity(cos_sim):\n",
    "    norm = (cos_sim + 1) / 2  # map (-1,1) ‚Üí (0,1)\n",
    "    scaled = 0.1 + 0.9 * norm # map (0,1) ‚Üí (0.1,1.0)\n",
    "    return round(scaled, 4)\n",
    "\n",
    "# --- Main Processor ---\n",
    "def summarize_and_score(df, model_name, output_csv):\n",
    "    embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    prototype_sentence = \"gold price, bullion, inflation, gold futures, safe haven\"\n",
    "    proto_emb = embed_model.encode(prototype_sentence, convert_to_tensor=True)\n",
    "\n",
    "    cause_list = []\n",
    "    effect_list = []\n",
    "    cause_effect_summary_list = []\n",
    "    general_summary_list = []\n",
    "    general_embedding_list = []\n",
    "    similarity_scores = []\n",
    "    causal_only_flags = []\n",
    "    bad_rows = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        try:\n",
    "            content = row['Content']\n",
    "\n",
    "            # Causal extraction\n",
    "            causal_prompt = create_causal_prompt(content)\n",
    "            causal_response = run_ollama_prompt(model_name, causal_prompt)\n",
    "            causes = extract_causal_pairs(causal_response) if causal_response else []\n",
    "\n",
    "            if causes:\n",
    "                cause_texts = [c['cause'] for c in causes]\n",
    "                effect_texts = [c['effect'] for c in causes]\n",
    "                joined_cause_effect = [\"Cause: \" + c['cause'] + \" --> Effect: \" + c['effect'] for c in causes]\n",
    "\n",
    "                cause_text = \" || \".join(cause_texts)\n",
    "                effect_text = \" || \".join(effect_texts)\n",
    "                cause_effect_summary = \" || \".join(joined_cause_effect)\n",
    "            else:\n",
    "                cause_text = \"No gold cause identified.\"\n",
    "                effect_text = \"No gold effect identified.\"\n",
    "                cause_effect_summary = \"No gold causality found.\"\n",
    "\n",
    "            # General summarization\n",
    "            general_prompt = create_general_prompt(content)\n",
    "            general_response = run_ollama_prompt(model_name, general_prompt)\n",
    "            gold_general_summary = extract_general_summary(general_response) if general_response else \"No gold-related content found.\"\n",
    "\n",
    "            # Fallback: if no summary but causes exist\n",
    "            if gold_general_summary == \"No gold-related content found.\" and causes:\n",
    "                fallback_summary = f\"This article discusses gold causally, mentioning: {', '.join(cause_texts)}.\"\n",
    "                gold_general_summary = fallback_summary\n",
    "                causal_only_flags.append(True)\n",
    "            else:\n",
    "                causal_only_flags.append(False)\n",
    "\n",
    "            # Embedding the general summary\n",
    "            general_emb = embed_model.encode(gold_general_summary, convert_to_numpy=True).tolist()\n",
    "\n",
    "            # Relevance scoring\n",
    "            summary_emb = embed_model.encode(cause_effect_summary, convert_to_tensor=True)\n",
    "            cos_sim = util.cos_sim(summary_emb, proto_emb).item()\n",
    "            relevance_score = normalize_similarity(cos_sim)\n",
    "\n",
    "            # Save\n",
    "            cause_list.append(cause_text)\n",
    "            effect_list.append(effect_text)\n",
    "            cause_effect_summary_list.append(cause_effect_summary)\n",
    "            general_summary_list.append(gold_general_summary)\n",
    "            general_embedding_list.append(general_emb)\n",
    "            similarity_scores.append(relevance_score)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Warning: Skipping row {idx} due to error: {e}\")\n",
    "            bad_rows.append(row)\n",
    "\n",
    "    # Create clean DataFrame\n",
    "    good_df = df.drop(index=[row.name for row in bad_rows])\n",
    "\n",
    "    # Add processed columns\n",
    "    good_df['gold_cause'] = cause_list\n",
    "    good_df['gold_effect'] = effect_list\n",
    "    good_df['gold_cause_effect_summary'] = cause_effect_summary_list\n",
    "    good_df['gold_general_summary'] = general_summary_list\n",
    "    good_df['gold_general_embedding'] = general_embedding_list\n",
    "    good_df['gold_relevance_score'] = similarity_scores\n",
    "    good_df['causal_only'] = causal_only_flags\n",
    "\n",
    "    good_df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Finished processing. Output saved to {output_csv}\")\n",
    "\n",
    "    # Save bad rows\n",
    "    if bad_rows:\n",
    "        bad_rows_df = pd.DataFrame(bad_rows)\n",
    "        bad_rows_output = output_csv.replace(\".csv\", \"_bad_rows.csv\")\n",
    "        bad_rows_df.to_csv(bad_rows_output, index=False)\n",
    "        print(f\"\\nüö® Saved bad rows separately to {bad_rows_output}\")\n",
    "\n",
    "# --- RUNNING SECTION --- #\n",
    "if __name__ == \"__main__\":\n",
    "    df = df_articles  # Your sample DataFrame\n",
    "    output_csv = r\"C:\\Users\\balaj\\code_files\\Documents\\Brahmanda\\context_aware_risk_methodology\\event_causal_prediction_system\\data\\causal_gold_articles_full_llama3.2.csv\"\n",
    "    model_name = \"llama3.2\"\n",
    "\n",
    "    summarize_and_score(df, model_name, output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
